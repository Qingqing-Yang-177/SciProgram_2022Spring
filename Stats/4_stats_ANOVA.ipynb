{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANOVA\n",
    "\n",
    "This chapter is adapted from Danielle Navarro's excellent Learning Statistics with R book and adapted for Python by Todd Gureckis (2020) and Shannon Tubridy (2021)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy.random as npr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import pingouin as pg\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANOVA\n",
    "\n",
    "In the stats_regression_part1.ipynb notebook we constructed linear models that attempt to describe some outcome measurement (like parent grumpiness) as a function of one or more predictor variables like quantity of parent sleep or baby sleep.\n",
    "\n",
    "We could also describe ANOVA in the same way: we are attempting to account for variance in some outcome measure based on one or more predictor or grouping variables. \n",
    "\n",
    "In fact, in many cases regression and ANOVA are different ways of examining the same model. The key difference for our current purposes is that we will _usually_ use regression when the predictor variable(s) are continuous or otherwise numerically meaningful, and ANOVA when the predictor variables are categorical or are factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One way ANOVA\n",
    "\n",
    "When we have one experimental manipulation with multiple levels, like different experimental groups, and we want to assess the effect on an outcome variable we can do one-way ANOVA.\n",
    "\n",
    "First let's simulate some data in an experiment where we have four groups of participants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will make use of the numpy.random function normal() which takes in a mean, a standard deviation, and the number of samples desired and returns an array with numbers sampled from a Gaussian distribution with mean and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 10\n",
    "sd = 1\n",
    "n_samples = 20\n",
    "\n",
    "# get 20 samples from a normal distribution with mean 10 and sd 1\n",
    "random_nums = npr.normal(mu, sd, n_samples)\n",
    "\n",
    "sns.displot(random_nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We'll make fake data by getting data from some number of trials for each participant. \n",
    "\n",
    "Each participant will be assigned to one experimental group, and the groups will differ in the mean of the Gaussian distribution we are sampling from. This will have the effect of giving us a difference, on average, between groups but also some variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# four levels of exp_condition factor\n",
    "exp_conditions = ['A', 'B', 'C', 'control']\n",
    "\n",
    "# each participant will do 50 trials\n",
    "n_trials = 50\n",
    "\n",
    "# 25 people per exp_condition\n",
    "participants_per_group = 25\n",
    "\n",
    "total_participants = len(exp_conditions) * participants_per_group\n",
    "\n",
    "# make a list of participant numbers using list comprehension\n",
    "# for each i between 1 and number of participants, make a string\n",
    "# that is e.g., `sub-1`, `sub-2`, etc\n",
    "# and put the results of all that into the sub_nums list\n",
    "sub_nums = [f'sub-{i}' for i in range(1, total_participants+1)]\n",
    "\n",
    "# use slicing to view the first four \n",
    "# elements of the sub_nums list\n",
    "sub_nums[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the list comprehension at the end of the last cell\n",
    "# is equivalent to this for loop:\n",
    "\n",
    "# set an empty to list so \n",
    "# we can append values to it\n",
    "sub_nums = []\n",
    "\n",
    "# loop over numbers 1 to the number of people we have +1\n",
    "# and make an id that is of the form 'sub-NN'\n",
    "for i in range(1, total_participants+1):\n",
    "    sub_nums.append(f'sub-{i}')\n",
    "    \n",
    "    \n",
    "sub_nums[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For loops using enumerate\n",
    "\n",
    "\n",
    "Sometimes we loop directly over an iterable object like a list:\n",
    "\n",
    "```\n",
    "for s in some_list:\n",
    "    print(s)\n",
    "```\n",
    "\n",
    "And sometimes we loop over a range of numbers and then use that to do some indexing on a list or other object:\n",
    "\n",
    "```\n",
    "some_list = ['a','b','c']\n",
    "\n",
    "for i in range(0,len(some_list)):\n",
    "    print(some_list[i])\n",
    "    \n",
    "```\n",
    "\n",
    "An alternative to those is the enumerate() function which takes an iterable (like a list) as input and returns both the index positions _and_ the values. This can be quite useful for times when we both want everything from the list and want the current index position on each loop:\n",
    "\n",
    "```\n",
    "some_list = ['a','b','c']\n",
    "\n",
    "for i, s in enumerate(some_list):\n",
    "    print(f'i = {i}')\n",
    "    print(f's = {s}')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reminder: 'f' strings are a way to combine strings and variables\n",
    "\n",
    "The f string is denoted by a leading f and then quotations around the rest. Strings or letters that you want to use use as is can just be entered in and will appear in red (in Jupyter). Any variables you can want to include go inside of curly brackets {} and their current value will be added into the fstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remind ourselves about the experimental variables we already defined\n",
    "print(exp_conditions)\n",
    "print(participants_per_group)\n",
    "print(sub_nums[:5])\n",
    "print(n_trials)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make some simulated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the experimental groups\n",
    "# for each one, generate 25 participants of random data\n",
    "# we can get 50 trials of data for each person and then\n",
    "# for each participant, get their average response to be used\n",
    "# in our ANOVA\n",
    "\n",
    "# set up some empty lists so we can append results as we \n",
    "# got through the loop\n",
    "exp_group = []\n",
    "avg_response = []\n",
    "\n",
    "# use enumerate(). This will give us the index\n",
    "# position of each entry in exp_groups (stored in i)\n",
    "# as well as the group name itself (stored in 'group')\n",
    "for i, group in enumerate(exp_conditions):\n",
    "\n",
    "    # simulate individual participants:\n",
    "    for s in range(participants_per_group):\n",
    "        \n",
    "        # get n_trials worth of data for this 'person'\n",
    "        # we will use the index position taken from enumerate\n",
    "        # as the input for the mean value in \n",
    "        # npr.normal(mu, sd, n_samples)\n",
    "        s_trials = npr.normal(i, 1, n_trials)\n",
    "        \n",
    "        # get the average of this person's trial data\n",
    "        # and store it in the avg_response list\n",
    "        avg_response.append(np.mean(s_trials))\n",
    "        \n",
    "        # keep track of this person's experimental group\n",
    "        exp_group.append(group)\n",
    "    \n",
    "    \n",
    "# make a dataframe that has subject id, avg response, and group\n",
    "one_way_df = pd.DataFrame({'id': sub_nums,\n",
    "                          'response': avg_response,\n",
    "                          'exp_group': exp_group})\n",
    "\n",
    "\n",
    "one_way_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 'data' from 100 people assigned to each of four experimental groups and we have an average score for each person in each group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can vizualize the mean response within each group using sns.catplot():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x = 'exp_group', \n",
    "            y = 'response', \n",
    "            kind='bar',\n",
    "            data=one_way_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there is an effect of exp group on response, and we can test this statistically with a one way ANOVA.\n",
    "\n",
    "As mentioned above, there is a close link between ANOVA and linear regression. To start, we will set up our model using syntax we have already seen before in the regression notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneway_model = smf.ols(formula = 'response ~ C(exp_group)', data=one_way_df)\n",
    "oneway_model = oneway_model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To this point we have done *exactly* the same thing as fitting a regression model with the execption that we put C() around our predictor variable. This is to ensure that it is treated as a *categorical* variable. To get an ANOVA table from this we use sm.stats.anova_lm() and input the fit model we've already estimated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_table = sm.stats.anova_lm(oneway_model, typ=1)\n",
    "anova_table\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, well, well.. looks like an ANOVA result. Notice also that the anova_lm() function can take a typ= argument in addition to taking the fit model itself. This corresponds to the type 1, type 2, and type 3 sum of squares versions of ANOVA. We won't discuss specifics of their application here, but will simply note that flexibility of the anova_lm() function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our resulting ANOVA table has the info we would need to interpret and write up our results. In this case there seems to be a main effect of experimenteal group, as indicated by the PR(>F) value (the p value) being much less than zero. We also have the F statistic itself, along with the degrees of freedom.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = anova_table['df'][0]\n",
    "df2 = anova_table['df'][1]\n",
    "F = anova_table['df'][0]\n",
    "p_val = anova_table['PR(>F)'][0]\n",
    "\n",
    "results_string = f'F({df1}, {df2}) = F, p = {p_val}'\n",
    "results_string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Post-hoc pairwise comparisons\n",
    "\n",
    "Our ANOVA result indicates that the exp group has an effect on response, but doesn't tell which groups are different from each other. This is the domain of _post-hoc_ follow-up comparisons.\n",
    "\n",
    "There are a variety of ways to compute these comparisons. One common approach is to compute **Tukey's HSD** which will give us the significance of differences between each pairwise combination of groups in the data while maintaining Type I error expectation in the face of multiple comparisons.\n",
    "\n",
    "There is a Tukey HSD function in the statsmodel library. Let's import it and use it.\n",
    "\n",
    "The function takes in an `endog=` argument which is the outcome variable, a `groups=` argument which is an array of factors in our ANOVA (in this case we have only one), and a desired experiment-wide false alarm rate (alpha)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# perform Tukey's test\n",
    "tukey = pairwise_tukeyhsd(endog=one_way_df['response'],\n",
    "                          groups=one_way_df['exp_group'],\n",
    "                          alpha=0.05)\n",
    "\n",
    "print(tukey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row of the output from the Tukey's test shows us the two groups being compared (group 1 and group2), the average difference between them, the adjusted p value (accounting for multiple comparisons), and the confidence intervals on the difference score.\n",
    "\n",
    "In our simulated data, each group was different from every other group, but in real data this isn't necessarily the case, even if there is a main effect of group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two (or more) way ANOVA\n",
    "\n",
    "Many experiments will include a crossing of multiple experimental conditions or factors. \n",
    "\n",
    "For example we might have four participant groups and two kinds of tasks people are doing, and we can ask whether the experimental group has an effect on the responses, whether the task has an effect on the responses, and/or whether there is an interaction of those two factors on performance.\n",
    "\n",
    "We'll generate some data to include a second factor that we can examine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_conditions = ['A', 'B', 'C', 'control']\n",
    "trial_types = ['easy', 'hard']\n",
    "\n",
    "n_trials = 50\n",
    "\n",
    "participants_per_group = 25\n",
    "total_participants = len(exp_conditions) * participants_per_group\n",
    "\n",
    "# make a list of participant numbers using list comprehension\n",
    "sub_nums = [f'sub-{i}' for i in range(1, total_participants+1)]\n",
    "\n",
    "# loop over the experimental groups\n",
    "# for each one, generate 25 participants of random data\n",
    "# we can get 50 trials of data for each person and then\n",
    "# for each participant, get their average response to be used\n",
    "# in our ANOVA\n",
    "\n",
    "# set up some empty lists so we can append results as we \n",
    "# got through the loop\n",
    "exp_group = []\n",
    "avg_response = []\n",
    "t_types = []\n",
    "subs = []\n",
    "\n",
    "# use enumerate(). This will give us the index\n",
    "# position of each entry in exp_groups (stored in i)\n",
    "# as well as the group name itself (stored in 'group')\n",
    "for i, group in enumerate(exp_conditions):\n",
    "\n",
    "    # simulate individual participants:\n",
    "    for s in range(participants_per_group):\n",
    "        \n",
    "        for it, tr in enumerate(trial_types):\n",
    "        \n",
    "        \n",
    "            # get n_trials worth of data for this 'person'\n",
    "            # we will use the index position taken from enumerate\n",
    "            # as the input for the mean value in \n",
    "            # npr.normal(mu, sd, n_samples)\n",
    "            \n",
    "            # for each group except 'control', increase the mean by one\n",
    "            # if it's the hard condition\n",
    "            if group != 'control':\n",
    "                s_trials = npr.normal(i+it, 1, n_trials)\n",
    "            else:\n",
    "                s_trials = npr.normal(i, 1, n_trials)\n",
    "\n",
    "            # get the average of this person's trial data\n",
    "            # and store it in the avg_response list\n",
    "            avg_response.append(np.mean(s_trials))\n",
    "\n",
    "            # keep track of this person's experimental group\n",
    "            exp_group.append(group)\n",
    "            \n",
    "            # track the trial type\n",
    "            t_types.append(tr)\n",
    "            \n",
    "            # the subject number\n",
    "            subs.append(f'sub-{s}')\n",
    "    \n",
    "# make a dataframe that has subject id, avg response, and group\n",
    "two_way_df = pd.DataFrame({'id': subs,\n",
    "                          'response': avg_response,\n",
    "                          'exp_group': exp_group,\n",
    "                          'trial_type': t_types})\n",
    "\n",
    "\n",
    "two_way_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's plot the data using sns.catplot() but now adding the hue= argument so that we can account for two grouping or categorical variables.\n",
    "\n",
    "We'll also use the `kind='point'` argument to generate a plot of the type that is often used for plotting multi-way ANOVA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x = 'trial_type',\n",
    "            y = 'response', \n",
    "            hue = 'exp_group', \n",
    "            kind = 'point',\n",
    "            data=two_way_df)\n",
    "\n",
    "plt.ylim(-2,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these data it looks like the response varies based on the group (difference in response as we move across the x-axis) and there is also a difference based on trial type (hard trials usually associated with inreased response value compared to easy). \n",
    "\n",
    "Lastly, it looks like there might be an interaction between exp group and trial type: the effect of trial type does not seem to be the same in the control group compared to groups A, B, and C.\n",
    "\n",
    "Now we can do a two-way ANOVA to check all this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoway_model = smf.ols(formula = 'response ~ C(exp_group) + C(trial_type) + C(exp_group):C(trial_type)', \n",
    "                       data=two_way_df)\n",
    "\n",
    "twoway_model = twoway_model.fit()\n",
    "\n",
    "twoway_table = sm.stats.anova_lm(twoway_model, typ=2)\n",
    "twoway_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at our formula for the model:\n",
    "\n",
    ">`'response ~ C(exp_group) + C(trial_type) + C(exp_group):C(trial_type)'`\n",
    "\n",
    "What we've done is include our two categorial predictors (exp_group and trial_type), specifying them as categorical (C()), and then also asked the model to estimate the effect of the interaction between those groups using the `:` to join them.\n",
    "\n",
    "For convenience one can also use the following syntax in order to get a full crossing (main effect and interaction) of the factors:\n",
    "\n",
    ">`'response ~ C(exp_group)*C(trial_type)'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twoway_model = smf.ols(formula = 'response ~ C(exp_group)*C(trial_type)', \n",
    "                       data=two_way_df)\n",
    "\n",
    "twoway_model = twoway_model.fit()\n",
    "\n",
    "twoway_table = sm.stats.anova_lm(twoway_model, typ=2)\n",
    "twoway_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again we can use anova_lm() on our ols results to obtain the ANOVA table. Now we see a row for each factor, along with p values for the main effect, and the interaction row (C(exp_group):C(trial_type)).\n",
    "\n",
    "In our case we have significant main effects as well as a significant interaction, as indicated by the small p value (PR(>F).\n",
    "\n",
    "**NOTE**: Python is displaying our very small p values in scientific notation. So 1.29e-166 means take 1.29 and move the decimal 166 places to the left. This is a very small number.  \n",
    "\n",
    "Perhaps a clearer example is that 5e-2 is .05:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 5e-2\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will not spend much time talking about ANOVA follow-up analyses for interactions because it is not as straightforward as doing Tukey's test. Fundamenally what we want to do is understand the interaction. One approach is to plot the data like before and the interaction is often clear.\n",
    "\n",
    "Another approach is to use pg.pairwise_ttests() to get the pairwise comparison between all crossings of the factors and focus on the rows that have a combined Contrast, and look for places where the significance varies across conditions.\n",
    "\n",
    "The pg.pairwise_ttests() function takes in the dependent variable (dv=) the grouping factors (between=[]), the data, and an optional adjustment for multiple comparisons (padjust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.pairwise_ttests(dv='response', \n",
    "                   between=['exp_group', 'trial_type'], \n",
    "                   data=two_way_df, \n",
    "                   padjust='bonferroni')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output gives us many t-test results, but we are interested in the interaction. In particular, we are interested in whether the effect of easy and hard trials is the same for each experimental group. The last four rows here show us those results: for groups A, B, and C, the test between easy and hard is significnat (p<.05), whereas for the control group that comparison is not significant. That is our interaction."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
