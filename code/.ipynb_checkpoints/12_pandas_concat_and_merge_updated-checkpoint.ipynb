{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining data frames\n",
    "\n",
    "This notebook reviews _concatenating_ dataframes, or stacking them vertically, and introduces _merging_ dataframes which allows combining two dataframes where the data are linked based on values in one more columns of the frames.\n",
    "\n",
    "### Goals of this notebook:\n",
    "\n",
    "Introduce tools to quickly enable tasks like combining these two dataframes\n",
    "\n",
    "| sub_id | exp_condition | accuracy |\n",
    "| --- | --- | --- |\n",
    "| sub-73 | group_2 | .843 |\n",
    "| sub-43 | group_2 | .343 |\n",
    "| sub-81 | group_1 | .897 |\n",
    "\n",
    "\n",
    "\n",
    "| sub_id | age_group | location |\n",
    "| --- | --- | --- |\n",
    "| sub-73 | child | NYC |\n",
    "| sub-43 | child | NYC |\n",
    "| sub-81 | adolescent | BOS |\n",
    "\n",
    "\n",
    "So that we have all of our data together in a frame like this:\n",
    "\n",
    "| sub_id | exp_condition | accuracy | age_group | location |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| sub-73 | group_2 | .843 | child | NYC |\n",
    "| sub-43 | group_2 | .343 | child | NYC |\n",
    "| sub-81 | group_1 | .897 | adolescent | BOS |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating versus Merging\n",
    "\n",
    "**Combining dataframes vertically, or _concatenating_ (adding rows)**\n",
    "\n",
    "Sometimes you want to 'stack' dataframes that have (mostly) the same columns.\n",
    "\n",
    "A common use for this is when you have experiment data from individual participants and you want to combine them into a dataframe that has data from all participants. \n",
    "\n",
    "This is usually done using the pandas `concat()` function which we have seen already. \n",
    "\n",
    "It lets us go from separate dataframes like this:\n",
    "\n",
    "\n",
    "| sub_id | task | accuracy |\n",
    "| --- | --- | --- |\n",
    "| sub-113 | working_memory | .34 |\n",
    "| sub-113 | word_generation | .28 |\n",
    "\n",
    "| sub_id | task | accuracy |\n",
    "| --- | --- | --- |\n",
    "| sub-045 | working_memory | .63 |\n",
    "| sub-045 | word_generation | .56 |\n",
    "| sub-045 | attention_control | .72 |\n",
    "\n",
    "\n",
    "To a single frame like this:\n",
    "\n",
    "| sub_id | task | accuracy |\n",
    "| --- | --- | --- |\n",
    "| sub-113 | working_memory | .34 |\n",
    "| sub-113 | word_generation | .28 |\n",
    "| sub-045 | working_memory | .63 |\n",
    "| sub-045 | word_generation | .56 |\n",
    "| sub-045 | attention_control | .72 |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A function for simulating data\n",
    "\n",
    "Throughout this notebook we will want to generate simulated data for participants in an experiment.\n",
    "\n",
    "To simplify that and make code more readable I have defined a function that takes in some arguments and gives back simulated data for a participant in an experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_participant_data(uid, \n",
    "                          n_trials = 100, \n",
    "                          cond_diffs = True, \n",
    "                          response_opts = [1,2,3,4], \n",
    "                          exp_conditions = ['easy', 'hard']):\n",
    "    '''\n",
    "    Makes fake participant data and returns a dataframe.\n",
    "\n",
    "            Parameters:\n",
    "                    uid (str, int): An id for the participant\n",
    "                    n_trials  (int): Number of trials worth \n",
    "                                        of data in each exp_condition\n",
    "                                        \n",
    "                    cond_diffs (boolean): Whether to simulate \n",
    "                                            data with differences \n",
    "                                            between conditions\n",
    "                                            \n",
    "                    response_opts (list): the possible reponse keys that\n",
    "                                            the participant can press\n",
    "                    \n",
    "                    \n",
    "                    exp_conditions (list): The names of various experimental \n",
    "                                            conditions. If cond_diffs is True, then\n",
    "                                            these trial types will vary in their \n",
    "                                            mean response time\n",
    "\n",
    "            Returns:\n",
    "                    df (dataframe): A dataframe of simulated data \n",
    "                                        with one row for each trial \n",
    "                                        and these columns:\n",
    "                                            uid: participant id\n",
    "                                            trial_type: experimental condition\n",
    "                                            resp: response key pressed\n",
    "                                            acc: accuracy (1/0)\n",
    "                                            RT: response time\n",
    "    '''\n",
    "     \n",
    "    # total number of experimental conditions:\n",
    "    n_conditions = len(exp_conditions)\n",
    "    \n",
    "    # Loop over \"trials of the experiment\"\n",
    "    # -----\n",
    "    # In each loop, take one experimental condition and generate \n",
    "    # key presses (response), accuracy (acc), and response time for \n",
    "    # each of n_trials\n",
    "    \n",
    "    # keep track of exp condition for each trial:\n",
    "    trial_types = []\n",
    "    \n",
    "    # keep track of the key pressed on each trial\n",
    "    trial_responses = []\n",
    "    \n",
    "    # keep track of response time on each trial\n",
    "    trial_rts = []\n",
    "    \n",
    "    # keep track of accuracy on each trial\n",
    "    trial_acc = []\n",
    "    \n",
    "\n",
    "    # Loop over each experimental_condition. Enumerate returns two values: \n",
    "    #     first is the index on each loop, second is the actual value\n",
    "    for trial_type_idx, trial_type in enumerate(exp_conditions):\n",
    "        \n",
    "        # If there are condition differences in response time set \n",
    "        # the mean RT for this condition to be the trial_type_idx+2\n",
    "        #\n",
    "        # This will make the first condition have mean RT of 2\n",
    "        # (0+2), the next will be mean RT of 3 (1+1), etc\n",
    "        \n",
    "        if cond_diffs:\n",
    "            mean_rt = trial_type_idx+2\n",
    "        else:\n",
    "            mean_rt = 1\n",
    "        \n",
    "        # get n_trials worth random responses from the response_opts list\n",
    "        response = np.random.choice(response_opts, n_trials)\n",
    "        \n",
    "        # get n_trials worth of binary (1 or 0) integer accuracy scores\n",
    "        acc = np.random.randint(0, 2, n_trials)\n",
    "        \n",
    "        # Get n_trials of response times using the mean_rt from above\n",
    "        # take the absolute value because all response times are positive numbers\n",
    "        rt = abs(npr.normal(mean_rt, 1, n_trials))\n",
    "\n",
    "        # make a list n_trials long that tags each of the response, acc, and rts\n",
    "        # as being of this trial type\n",
    "        tts = [trial_type]*n_trials\n",
    "        \n",
    "        # Store all the info for this loop of the experimental conditions\n",
    "        # Use extend() rather than append() because the things we are adding\n",
    "        # to lists are arrays and we want to add the individual values\n",
    "        # to the overall trial_* lists\n",
    "        \n",
    "        trial_types.extend(tts)\n",
    "        trial_responses.extend(response)\n",
    "        trial_rts.extend(rt)\n",
    "        trial_acc.extend(acc)\n",
    "    \n",
    "    # After looping over the trial types and getting trial-level simulated\n",
    "    # data, make a dataframe from a dictionary of column names (keys) and\n",
    "    # data values\n",
    "    trial_df = pd.DataFrame({'uid': str(uid),\n",
    "                       'response': trial_responses,\n",
    "                       'acc': trial_acc,\n",
    "                       'trial_type': trial_types,\n",
    "                       'RT': trial_rts\n",
    "                      })\n",
    "    \n",
    "    # return a dataframe with all the data in it\n",
    "    return trial_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the data simulation function\n",
    "\n",
    "\n",
    "Once we've defined the function we can execute all that code in a single line.\n",
    "\n",
    "At a minimum the function takes in a user id. \n",
    "\n",
    "In that case the default arguments will be used to generate 100 trials worth of data in an easy and hard experimental condition and the response times will be longer in the hard condition (due to cond_diffs=True)\n",
    "\n",
    "```python\n",
    "make_participant_data(uid, \n",
    "                      n_trials = 100, \n",
    "                      cond_diffs = True, \n",
    "                      response_opts = [1,2,3,4], \n",
    "                      exp_conditions = ['easy', 'hard'])\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Use the function to make simulated data for one person with 50 trials per condition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the response times in the two trial type (exp_conditions)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make some data with three experimental conditions and no response time differences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make individual dataframes\n",
    "\n",
    "For each participant in the list `all_subs = ['sub-18','sub-19', 'sub-33', 'sub-08']` use the `make_participant_data()` function with n_trials = 100 to make individual dataframes. The individual dataframes should be stored in a list called `df_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of dataframes with participant data\n",
    "all_subs = ['sub-18','sub-19', 'sub-33', 'sub-08']\n",
    "df_list = []\n",
    "\n",
    "# fill in code here:\n",
    "for sub_id in all_subs:\n",
    "    df_list.append(make_participant_data(sub_id))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each dataframe has data for one person for a series of trials in the experiment. Rows correspond to trials and columns are different kinds of data we measured. \n",
    "\n",
    "### Using `pd.concat()` to combine or stack dataframes vertically\n",
    "\n",
    "\n",
    "\n",
    "`pd.concat()` takes a list of dataframes as input and returns a dataframe that combines all of the input dataframes vertically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can do it this way if individual dataframes are stored in \n",
    "# their own variables\n",
    "pd.concat([df1, df2, df3, df4], ignore_index=True)\n",
    "\n",
    "# the ignore_index=True will ignore the index (row labels)\n",
    "# in the original dataframes and just renumber everything\n",
    "# 0 to n-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Or this code which will do the same thing equivalent if you\n",
    "# already have a list of dataframes\n",
    "all_participants = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "all_participants\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use dataframe['col'].unique() to see which subject-ids are in the combined dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get average data values for each participant or trial type\n",
    "\n",
    "In previous sections we used `.groupby()` to take different views on our data by combining them according to different value in the dataframe.\n",
    "\n",
    "For example, let's check the average of the columns in the dataframe after separating the data according to trial_type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use unique to remind us of the different trial_types\n",
    "all_participants['trial_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the average accuracy and response time for \n",
    "# each trial type:\n",
    "all_participants.groupby('trial_type', as_index=False)['RT'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or get lots of descriptive stats for the 'RT' column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_participants.groupby('trial_type')['RT'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get mean RT for easy and hard trials for each participant in `all_participants` dataframe\n",
    "\n",
    "Now get the average response time for each trial type within each participant id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean response time (RT column) for each person\n",
    "# in the uid column separated by trial type:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make a bar graph with percent correct (acc column) as the y value and a separate bar for each participant in the all_participants dataframe\n",
    "\n",
    "**hint**: use seaborn catplot(). Catplot with kind=bar will give us the average of whatever we put in the y= value. \n",
    "\n",
    "In our data the acc column is binary 1/0 and the average of that will be the percent correct, or proportion of entries that are equal to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a plot for percent correct for each person:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could keep on analyzing the data, but the main thing from this section is to notice how using pd.concat() and inputting a list of dataframes makes a new dataframe with all the input df's stacked up vertically. If they have the same columns the result makes sense.\n",
    "\n",
    "You can also use pd.concat() if df's have different columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make some simulated trial data\n",
    "df1 = make_participant_data('sub-99')\n",
    "df1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a different dataframe with some other columns\n",
    "df99 = pd.DataFrame({'uid': 'sub-88', \n",
    "                     'response_time': np.random.uniform(1000,5000, 6)})\n",
    "df99.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use pd.concat() to stack df1 and df99:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df1, df99]\n",
    "\n",
    "combined_df = pd.concat(df_list, ignore_index=True)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the df's to be concatenated don't have the same columns, the output has all of the columns that appeared in any of the input list. \n",
    "\n",
    "Any rows of the data that come from a dataframe that didn't have that column get NaN (not a number) in that cell.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging dataframes\n",
    "\n",
    "The preceding examples showed __concatenating__ that glues together some dataframes top to bottom.\n",
    "\n",
    "Another common need is to combine dataframes that have different information for the same person or other unit.\n",
    "\n",
    "We want to go from these two frames:\n",
    "\n",
    "\n",
    "| sub_id | exp_condition | accuracy |\n",
    "| --- | --- | --- |\n",
    "| sub-73 | group_2 | .843 |\n",
    "| sub-43 | group_2 | .343 |\n",
    "| sub-81 | group_1 | .897 |\n",
    "\n",
    "\n",
    "\n",
    "| sub_id | age_group | location |\n",
    "| --- | --- | --- |\n",
    "| sub-73 | child | NYC |\n",
    "| sub-43 | child | NYC |\n",
    "| sub-81 | adolescent | BOS |\n",
    "\n",
    "\n",
    "To one like this where information is linked based on the sub_id value\n",
    "\n",
    "| sub_id | exp_condition | accuracy | age_group | location |\n",
    "| --- | --- | --- | --- | --- |\n",
    "| sub-73 | group_2 | .843 | child | NYC |\n",
    "| sub-43 | group_2 | .343 | child | NYC |\n",
    "| sub-81 | group_1 | .897 | adolescent | BOS |\n",
    "\n",
    "\n",
    "\n",
    "In the next examples we will use `pd.merge()` to combine 'experiment data' from our participants that we already made with 'demographics' data for the same people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell defines a function that takes in a participant id (uid) and returns a dataframe that randomly assigns them to a location (urban, rural) and an age_group (child, adult)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convenience function to get random demographic info for a person\n",
    "def make_demo_data(uid, \n",
    "                   locations= ['urban', 'rural'], \n",
    "                   age_group = ['child', 'adult']):\n",
    "      \n",
    "        \n",
    "    # make dataframe using a randomly selected value from the locations and\n",
    "    # age_groups lists\n",
    "    # np.random.choice() takes in an array of strings or numbers and returns \n",
    "    # one of them selected at random\n",
    "    demo_df = pd.DataFrame({'uid': [uid],\n",
    "                            'location': [np.random.choice(locations)],\n",
    "                            'age_group': [np.random.choice(age_group)]\n",
    "                           })\n",
    "    return demo_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use it like this for subject with id sub-101:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make some simulated trial data for sub-101 using the \n",
    "# make_participant_data function:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do the wrong thing:\n",
    "\n",
    "Try concatenating the two dataframes we just made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenating didn't throw away any data but it also didn't result in a very useful dataframe. \n",
    "\n",
    "The demographics info for sub101 is separate from the other data instead of \"tidy\" where each row has info for all of the relevant variables.\n",
    "\n",
    "This will become even more clear when we have multiple people each of whom might be child or adult and want to do analyses where we look at trial performance based on demographics grouping. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# umake new experimental for four people using the\n",
    "# make_participant_data() function\n",
    "\n",
    "\n",
    "# use pd.concat to put them together \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use make_demo_data() to get demographic data for the same sub-id's as above \n",
    "# and combine them into a group dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `pd.merge()`\n",
    "\n",
    "To combine or trial data and the demographics info that are in separate dataframes we can use pd.merge() like this:\n",
    "\n",
    "```python\n",
    "df = pd.merge(left=dataframe1, right=dataframe2)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pd.merge() to combine trial and demographics data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our output now has all the columns we want, and the demographic data values are lined up with the experimental data for each person listed in the uid column.\n",
    "\n",
    "When we used merge() we gave it two inputs: `left=` and `right=`. \n",
    "\n",
    "These inputs corresponded to the dataframes we want to merge.\n",
    "\n",
    "By default, merge() looks for any columns with the same name in the two input dataframes. Then it takes those columns and lines up the dataframes according to the values in them. \n",
    "\n",
    "In our case there was a 'uid' column in both dataframes and so wherever those values overlapped the columns were combined.\n",
    "\n",
    "We can also specify which column values should be matched by including the `on=` argument to merge():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `on=` argument is especially useful if you have dataframes with different column names for the same underlying data. \n",
    "\n",
    "Here we will rename the 'uid' column in all_demo_df and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe rename function takes a dictionary mapping old names (keys) to new names (values)\n",
    "# inplace=True means change the existing dataframe (rather than outputting to a new variable)\n",
    "\n",
    "demo_data.rename(columns={'uid': 'ID_num', 'location': 'loc'}, \n",
    "                     inplace=True)\n",
    "demo_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try merging two dataframes that don't have overlapping column names:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the column names in each dataframe:\n",
    "print(trial_data.columns)\n",
    "print(demo_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# try to merge them\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That gave us an error: \"No common columns to perform merge on.\"\n",
    "\n",
    "The solution is to tell .merge() which columns in the left and right dataframe to merge on, or use for lining up the data.\n",
    "\n",
    "pd.merge() has optional input arguments called `left_on` and `right_on`. These can be used to give the column names to use (to treat as the same) in the left and right dataframes, respectively.\n",
    "\n",
    "We'll use it to tell pd.merge() to use the column called 'uid' in one dataframe to line up with the column called 'ID_num' in the other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we tell pd.merge to use 'uid' column in the \n",
    "# left= dataframe and line those values up with the\n",
    "# ID_num column in the right= dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see that it worked, lining up rows according to matching values in 'uid' and 'ID_num' columns in the two dataframes. \n",
    "\n",
    "It also kept both the original merge columns combined dataframe. \n",
    "\n",
    "We can drop one of those if we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del combined_df['ID_num']\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: practice merging dataframes\n",
    "\n",
    "The next cell defines another dataframe that gives us some information about people in age_groups child and adult."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_df = pd.DataFrame({'ages': ['child', 'adult'],\n",
    "         'expected_value': [0,99]})\n",
    "\n",
    "age_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll try to merge the `age_df` with our existing `combined_df` so that we have the `expected_value` for each age_group in the combined_df. \n",
    "\n",
    "In age_df the relevant column is called 'ages':\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the top of the combined_df\n",
    "# the relevant column is called age_group\n",
    "combined_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the combined_df and age_df\n",
    "# They should be merged using the 'age_group' column\n",
    "# in combined_df and the 'ages' column in the age_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the merged dataframe:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging on multiple columns\n",
    "\n",
    "In the last example we defined a little dataframe that had the expected value of something for both children and adults and we merged that into our trial and demographics data so that we had a new column with one value for children and another for adults.\n",
    "\n",
    "In this example we'll extend that and show how to line up to two dataframes based on the values in mutiple columns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new dataframe that has expected values \n",
    "# based on both age and location\n",
    "\n",
    "# make two lists that line up to make all combos of age and location\n",
    "ages = ['child', 'adult', 'child', 'adult']\n",
    "locations = ['urban', 'rural', 'rural', 'urban']\n",
    "\n",
    "# we have two lists that can be lined up in a dataframe\n",
    "print(ages)\n",
    "print(locations)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_loc_df = pd.DataFrame({'ages': ages,\n",
    "                           'locations': locations,\n",
    "                           'expected_value': [0, 80, 10, 90]})\n",
    "                           \n",
    "age_loc_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To merge the new expected values into the combined_df so that the value depends on matching both the age **and** the location we can use a **list of columns** as inputs to the `left_on` and `right_on` values in pd.merge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking mean of the expected_value column after using groupby() with loc and age_group shows that the expected value was merged into the dataframe based on values on both the age and location columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "This notebook reviewed pd.concat() for stacking dataframes vertically and pd.merge() for combining dataframes that are linked based on values in one or more columns.\n",
    "\n",
    "If you would like to dive deeper into the pandas merge() function I recommmend checking out chapter 3, section 7 of the Python Data Science Handbook by Jake VanderPlas:\n",
    "\n",
    "https://jakevdp.github.io/PythonDataScienceHandbook/\n",
    "\n",
    "https://jakevdp.github.io/PythonDataScienceHandbook/03.07-merge-and-join.html\n",
    "\n",
    "https://github.com/jakevdp/PythonDataScienceHandbook/blob/master/notebooks/03.07-Merge-and-Join.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
