{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANOVA\n",
    "\n",
    "This chapter is adapted from Danielle Navarro's excellent Learning Statistics with R book and adapted for Python by Todd Gureckis (2020) and Shannon Tubridy (2022)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goals for this notebook\n",
    "\n",
    "\n",
    "- ANOVA in Python\n",
    "    - plotting means and distributions of a numeric outcome variable within categorical groupings\n",
    "\n",
    "    - one-way ANOVA (a single categorical independent or grouping variable with more than two levels and a numeric outcome variable)\n",
    "    \n",
    "        - example: Do assessment scores vary across four different NYC elementary schools?\n",
    "        - example: Does the way people perceive others vary based on whether the rater is primed by reading stories with negative vs positive vs neutral content?\n",
    "    - two- or more way ANOVA (multiple categorical indepedendent or grouping variables and a single numeric outcome variable)\n",
    "        - example: \n",
    "    - repeated measures ANOVA (observations across levels of the independent variables are within person or entity)\n",
    "        - example: Do individual people's working memory capacities vary across morning, noon, and night?\n",
    "\n",
    "\n",
    "\n",
    "#### Data files used in this notebook\n",
    "\n",
    "- Brightspace / Content / data / meditation.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "hide_input"
    ]
   },
   "outputs": [],
   "source": [
    "# numpy for various numeric operations\n",
    "import numpy.random as npr\n",
    "import numpy as np\n",
    "\n",
    "# pands for dataframes\n",
    "import pandas as pd\n",
    "\n",
    "# seaborn and matplotlib for plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# scipy, statsmodels, and pingouin for stats tests\n",
    "import scipy.stats as stats\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import pingouin as pg\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In the regression notebook we constructed linear models that attempt to describe some outcome measurement (like mood) as a function of one or more predictor variables like quantity of sleep or amount of work.\n",
    "\n",
    "\n",
    "ANOVA has a similar goal: try to account for variance in some outcome measure based on one or more predictor variables. \n",
    "\n",
    "The key difference for our current purposes is that we will _usually_ use regression when the predictor variable(s) are continuous or otherwise numerically meaningful, and ANOVA when the predictor variables are categorical or are factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One way ANOVA\n",
    "\n",
    "\n",
    "Common use case:\n",
    "\n",
    "- One experimental manipulation with multiple levels, like different experimental groups measured on working memory capacity\n",
    "\n",
    "- Analysis question: does the value of the outcome measure differ according to levels of the categorical independent variable?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulating data\n",
    "\n",
    "We'll simulate data from four groups of participants.\n",
    "\n",
    "Random samples from a normal distribution using numpy:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "mu = 0\n",
    "sd = 1\n",
    "n_samples = 100\n",
    "\n",
    "np.random.normal(mu, sd, n_samples)\n",
    "```\n",
    "\n",
    "The numpy.random normal() function takes arguments:\n",
    "\n",
    "- mu: mean of the distribution\n",
    "- sd: standard deviation of the distribution\n",
    "- n_samples: how many random samples you want\n",
    "\n",
    "The result is an array of random number(s) drawn from a normal distribution with the mean and sd as indicated. The probability of any number being chosen is given by the normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a sample of numbers from a normal distribution with mean 1 \n",
    "# and sd 1 and histogram it\n",
    "\n",
    "\n",
    "# seaborn displot for histograms can take a single input (the numbers)\n",
    "# to histogram:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making simulated participant data overview\n",
    "\n",
    "We'll make fake data by getting data from some number of trials for each simulated participant in the \"experiment\". \n",
    "\n",
    "1. Each participant will be assigned to one experimental group\n",
    "2. Participant data will come from random samples from a normal distribution using numpy\n",
    "3. The experimental groups will differ in the mean of the Gaussian distribution we are sampling from\n",
    "4. This will have the effect of giving us a difference, on average, between groups but also some variability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Experimental details\n",
    "\n",
    "Four levels of experimental condition factor:\n",
    "['A', 'B', 'C', 'control']\n",
    "\n",
    "There will be 25 people per experimental condition\n",
    "\n",
    "Each participant will do 50 trials\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list with the experimental conditions (exp_condition)\n",
    "exp_conditions = ['A', 'B', 'C', 'control']\n",
    "\n",
    "# set number of participants per group:\n",
    "participants_per_group = 25\n",
    "\n",
    "# each participant will do 50 trials:\n",
    "n_trials = 50\n",
    "\n",
    "# get the total number of participants in the experiment:\n",
    "total_participants = participants_per_group * len(exp_conditions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of participant numbers:\n",
    "# for each i between 1 and number of participants, make a string\n",
    "# that is e.g., `sub-1`, `sub-2`, etc\n",
    "# and put the results of all that into a list called sub_nums\n",
    "\n",
    "# empty list to append to:\n",
    "sub_nums = []\n",
    "\n",
    "\n",
    "# loop and make subject ids and store them in sub_nums list:\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative to for loop: LIST COMPREHENSION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign participants to experimental groups\n",
    "\n",
    "Logic: \n",
    "\n",
    "1. Make a list of experimental conditions that has same length as number of participants and is split evenly between the four conditions in exp_conditions list (`cond_assignments`)\n",
    "\n",
    "2. Use numpy.random.shuffle() function to randomize the order of experimental conditions in the `cond_assignments` list generated in step 1\n",
    "\n",
    "3. During simulated data collection, participant N will be assigned to the experimental group indicated at position N in the `cond_assignments` list. That cond_assignment value will be used to (a) randomly sample data with different mean values based on the experimental condition for that person; (b) group the data by experimental condition for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Make a list of exp conditions that has same length as number of participants\n",
    "# This can be achieved by taking our exp_condition list (length = 4) and multiplying\n",
    "# it by the number of participants per group (25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Use numpy.random.shuffle() to randomize\n",
    "# the order of cond_assignments\n",
    "# This is an inplace function so it will change our variable directly\n",
    "np.random.shuffle(cond_assignments)\n",
    "cond_assignments\n",
    "                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. For simulating data, make a dictionary that will give us the average response value\n",
    "# for each of the experimental groups\n",
    "# This will be the mean that we pass to numpy.random.normal(mean, sd, n_samples) \n",
    "# in order to get 'data' for each person\n",
    "mean_dict = {'A': 10, \n",
    "             'B': 11, \n",
    "             'C': 10.5, \n",
    "             'control': 12}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For loops using enumerate\n",
    "\n",
    "To generate the data we will loop over our list of participant ids and for each one we will get an experimental group assignment from the cond_assignments list.\n",
    "\n",
    "We will use the enumerate() function in our for loop so that on each loop we get the participant id value as well as the index position of that value in the overall sub_nums list.\n",
    "\n",
    "Here are some reminders about different ways to do for loops.\n",
    "\n",
    "\n",
    "Sometimes we loop directly over an iterable object like a list:\n",
    "\n",
    "```\n",
    "\n",
    "some_list = ['person1', 'person2','person3']\n",
    "for s in some_list:\n",
    "    print(s)\n",
    "```\n",
    "\n",
    "The variable `s` will sequentially take on the values 'person1', then 'person2', etc and that value will be printed inside the loop.\n",
    "\n",
    "\n",
    "And sometimes we loop over a range of numbers and then use that to do some indexing on a list or other object:\n",
    "\n",
    "```\n",
    "some_list = ['a','b','c']\n",
    "\n",
    "for i in range(0,len(some_list)):\n",
    "    print(some_list[i])\n",
    "    \n",
    "```\n",
    "\n",
    "In this example, on each loop the variable `i` will take on one of the values 0 up to the length of the list minus 1, sequentially, and then that gets used inside the loop to access elements of `some_list` using bracket indexing.\n",
    "\n",
    "\n",
    "An alternative to those is the enumerate() function which takes an iterable (like a list) as input and returns both the index positions _and_ the values. This can be quite useful for times when we both want everything from the list and want the current index position on each loop:\n",
    "\n",
    "```\n",
    "some_list = ['a','b','c']\n",
    "\n",
    "for i, s in enumerate(some_list):\n",
    "    print(f'i = {i}')\n",
    "    print(f's = {s}')\n",
    "```\n",
    "\n",
    "In the enumerate example, `i` will take on the values 0 to the length of the list, one at a time, and `s` will take on the corresponding entry from some_list. On each iteration of the loop we have access to the current index position in `some_list` as well as the value at that position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make some simulated data\n",
    "\n",
    "1) Loop over the participant list using enumerate.\n",
    "\n",
    "2) For each participant, look up their experimental condition in the cond_assignments list using the current index value returned by enumerate.\n",
    "\n",
    "3) Use that person's group assignment as a key for the `mean_dict` dictionary. The returned value is the average response value for people in that group.\n",
    "\n",
    "4) Use numpy.random.normal() in combination with the mean value from step 3 to get random data for this person sampled from a random normal distribution with mean for that group\n",
    "\n",
    "5) Compute the average of that person's responses and store the value\n",
    "\n",
    "6) append the information from each participant to lists\n",
    "- participant ID\n",
    "- condition assignment (experimental group)\n",
    "- average response\n",
    "\n",
    "6) Make a dataframe summarizing the experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remind ourselves about the experimental variables we already defined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up some empty lists so we can append results as we \n",
    "# got through the loop\n",
    "sub_id_list = []\n",
    "sub_group_list = []\n",
    "avg_response = []\n",
    "\n",
    "\n",
    "# use enumerate to loop over people:\n",
    "\n",
    "    \n",
    "    # get this person's sub_id and condition assignment:\n",
    "    \n",
    "    \n",
    "    # get the mean response for this person based on their group assignment:\n",
    "    \n",
    "    \n",
    "    # get n_trials worth of random numbers for this person using the mean\n",
    "    # for their group as first input to np.random.normal():\n",
    "\n",
    "    # get the average response for this person\n",
    "    \n",
    "    \n",
    "    # append sub_id, experimental group, and average info to the empty lists\n",
    "    # we initialized outside of the loop\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "# Loop is over, make a dataframe with columns exp_group, sub_id, and response:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have 'data' from 100 people assigned to each of four experimental groups and we have an average score for each person in each group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing means for each group\n",
    "\n",
    "\n",
    "We can vizualize the mean response within each group using sns.catplot():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running one-way ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The apparent effect of exp group on response can be tested statistically with a one way ANOVA.\n",
    "\n",
    "There is a close link between ANOVA and linear regression. To start, we will set up our model using syntax we have already seen before in the regression notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneway_model = smf.ols(formula = 'response ~ C(exp_group)', data=one_way_df)\n",
    "oneway_model = oneway_model.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To this point we have done *exactly* the same thing as fitting a regression model with the execption that we put C() around our predictor variable. This is to ensure that it is treated as a *categorical* variable. \n",
    "\n",
    "To get an ANOVA table from this we use sm.stats.anova_lm() and input the fit model we've already estimated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_table = sm.stats.anova_lm(oneway_model, typ=1)\n",
    "anova_table\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like an ANOVA result. \n",
    "\n",
    "Notice also that the anova_lm() function can take a typ= argument in addition to taking the fit model itself. \n",
    "\n",
    "This corresponds to the type 1, type 2, and type 3 sum of squares versions of ANOVA. We won't discuss specifics of their application here, but will simply note that flexibility of the anova_lm() function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our resulting ANOVA table has the info we would need to interpret and write up our results. \n",
    "\n",
    "In this case there seems to be a main effect of experimental group, as indicated by the PR(>F) value (the p value) being much less than zero. \n",
    "\n",
    "We also have the F statistic itself, along with the degrees of freedom. The results object is a dataframe so we can access to individual values like this:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From there we can automatically generate a results string that is populated with the appropriate values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-hoc pairwise comparisons\n",
    "\n",
    "A significant one-way ANOVA results indicates that the exp group has an effect on response, but doesn't tell which groups are different from each other. \n",
    "\n",
    "For that we use post-hoc comparisons\n",
    "\n",
    "There are a variety of ways to compute these comparisons. \n",
    "\n",
    "One common approach is to compute **Tukey's HSD** which will give us the significance of differences between each pairwise combination of groups in the data while maintaining Type I error expectation in the face of multiple comparisons.\n",
    "\n",
    "There is a Tukey HSD function in the statsmodels library.\n",
    "\n",
    "The function takes in an `endog=` argument which is the outcome variable, a `groups=` argument which is an array of factors in our ANOVA (in this case we have only one), and a desired experiment-wide false alarm rate (alpha).\n",
    "\n",
    "\n",
    "```python\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "tukey_comparisons = pairwise_tukeyhsd(endog = array_of_outcome_values,\n",
    "                          groups = array_of_group_labels,\n",
    "                          alpha = overall false alarm rate)\n",
    "```\n",
    "\n",
    "The `array_of_outcome_values` and the `array_of_group_labels` should be of the same length, and each entry is lined up so that `array_of_group_labels` tells you what condition each value in `array_of_outcome_values` came from.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row of the output from the Tukey's test shows us the two groups being compared (group1 and group2), the average difference between them, the adjusted p value (accounting for multiple comparisons), and the confidence intervals on the difference score.\n",
    "\n",
    "In our simulated data, each group was different from every other group, but in real data this isn't necessarily the case, even if there is a main effect of group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two (or more) way ANOVA\n",
    "\n",
    "Many experiments will include a crossing of multiple experimental conditions or factors. \n",
    "\n",
    "For example:\n",
    "\n",
    "People are assigned to one of four participant groups (factor 1) and each person does either an easy or hard version of the task (factor 2). The outcome measure is the score on each task.\n",
    "\n",
    "- Does the experimental group have an effect on the responses?\n",
    "- Does the type of task (easy/hard) have an effect on the responses?\n",
    "- Is there an interaction of group and type of task performance?\n",
    "\n",
    "\n",
    "We'll generate some data to include a second factor that we can examine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell generates data in a two-way design with an interaction\n",
    "exp_conditions = ['A', 'B', 'C', 'control']\n",
    "\n",
    "\n",
    "trial_types = ['easy', 'hard']\n",
    "\n",
    "\n",
    "n_trials = 50\n",
    "\n",
    "participants_per_group = 25\n",
    "total_participants = len(exp_conditions) * participants_per_group\n",
    "\n",
    "# make a list of participant numbers using list comprehension\n",
    "sub_nums = [f'sub-{i}' for i in range(1, total_participants+1)]\n",
    "\n",
    "# loop over the experimental groups\n",
    "# for each one, generate 25 participants of random data\n",
    "# we can get 50 trials of data for each person and then\n",
    "# for each participant, get their average response to be used\n",
    "# in our ANOVA\n",
    "\n",
    "# set up some empty lists so we can append results as we \n",
    "# got through the loop\n",
    "exp_group = []\n",
    "avg_response = []\n",
    "t_types = []\n",
    "subs = []\n",
    "\n",
    "# use enumerate(). This will give us the index\n",
    "# position of each entry in exp_groups (stored in i)\n",
    "# as well as the group name itself (stored in 'group')\n",
    "for i, group in enumerate(exp_conditions):\n",
    "\n",
    "    # simulate individual participants:\n",
    "    for s in range(participants_per_group):\n",
    "        \n",
    "        for it, tr in enumerate(trial_types):\n",
    "        \n",
    "        \n",
    "            # get n_trials worth of data for this 'person'\n",
    "            # we will use the index position taken from enumerate\n",
    "            # as the input for the mean value in \n",
    "            # npr.normal(mu, sd, n_samples)\n",
    "            \n",
    "            # for each group except 'control', increase the mean by one\n",
    "            # if it's the hard condition\n",
    "            if group != 'control':\n",
    "                s_trials = npr.normal(i+it, 1, n_trials)\n",
    "            else:\n",
    "                s_trials = npr.normal(i, 1, n_trials)\n",
    "\n",
    "            # get the average of this person's trial data\n",
    "            # and store it in the avg_response list\n",
    "            avg_response.append(np.mean(s_trials))\n",
    "\n",
    "            # keep track of this person's experimental group\n",
    "            exp_group.append(group)\n",
    "            \n",
    "            # track the trial type\n",
    "            t_types.append(tr)\n",
    "            \n",
    "            # the subject number\n",
    "            subs.append(f'sub-{s}')\n",
    "    \n",
    "# make a dataframe that has subject id, avg response, and group\n",
    "two_way_df = pd.DataFrame({'id': subs,\n",
    "                          'response': avg_response,\n",
    "                          'exp_group': exp_group,\n",
    "                          'trial_type': t_types})\n",
    "\n",
    "\n",
    "two_way_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's plot the data using sns.catplot() using the hue= argument so that we can account for two grouping or categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The catplot() point plot\n",
    "\n",
    "The `kind='point` variant of catplot() produces figures of the type often presented with ANOVAs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In these data it looks like the response varies based on the group and there is also a difference based on trial type (hard trials usually associated with inreased response value compared to easy). \n",
    "\n",
    "Lastly, it looks like there might be an interaction between exp group and trial type: the effect of trial type does not seem to be the same in the control group compared to groups A, B, and C.\n",
    "\n",
    "Now we can do a two-way ANOVA to check all this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running two-way ANOVA in Python\n",
    "\n",
    "Fortunately, running a two (or more) way ANOVA is basically the same as a one-way with a slightly more complicated `formula=` argument:\n",
    "\n",
    "```python\n",
    "model = smf.ols(formula = 'outcome ~ C(factor1) + C(factor2) + C(factor1):C(factor2)', \n",
    "                       data=two_way_df)\n",
    "model_fit = model.fit()\n",
    "\n",
    "anova_table = sm.stats.anova_lm(twoway_model, typ=1)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run two way ANOVA on outcome 'response' for factors exp_group and trial_type\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at our formula for the model:\n",
    "\n",
    ">`'response ~ C(exp_group) + C(trial_type) + C(exp_group):C(trial_type)'`\n",
    "\n",
    "What we've done is include our two categorial predictors (exp_group and trial_type), specifying them as categorical (C()), and then also asked the model to estimate the effect of the interaction between those groups using the `:` to join them.\n",
    "\n",
    "For convenience one can also use the following syntax in order to get a full crossing (main effect and interaction) of the factors:\n",
    "\n",
    ">`'response ~ C(exp_group)*C(trial_type)'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run two-way ANOVA with full crossing by C(factor1)*C(factor2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again we can use `anova_lm()` on our ols results to obtain the ANOVA table. \n",
    "\n",
    "Now we see a row for each factor, along with p values for the main effect, and the interaction row (C(exp_group):C(trial_type)).\n",
    "\n",
    "In our case we have significant main effects as well as a significant interaction, as indicated by the small p value (PR(>F).\n",
    "\n",
    "**NOTE**: Python is displaying our very small p values in scientific notation. So 1.29e-166 means take 1.29 and move the decimal 166 places to the left. This is a very small number.  \n",
    "\n",
    "Perhaps a clearer example is that 5e-2 is .05:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 5e-2\n",
    "p == .05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will not spend much time talking about ANOVA follow-up analyses for interactions because it is not as straightforward as doing Tukey's test. \n",
    "\n",
    "Fundamenally what we want to do is understand the interaction. \n",
    "\n",
    "One approach is to plot the data like before and the interaction is often clear.\n",
    "\n",
    "Another approach is to use the pingouin pg.pairwise_ttests() to get the pairwise comparison between all crossings of the factors,  focus on the rows that have a combined Contrast, and look for places where the significance varies across conditions.\n",
    "\n",
    "The pg.pairwise_ttests() function takes in the dependent variable (dv=), the grouping factors (between=[]), the data, and an optional adjustment for multiple comparisons (padjust)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.pairwise_ttests(dv='response', \n",
    "                   between=['exp_group', 'trial_type'], \n",
    "                   data=two_way_df, \n",
    "                   padjust='bonferroni')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output gives us many t-test results, but we are interested in the interaction. In particular, we are interested in whether the effect of easy and hard trials is the same for each experimental group. The last four rows here show us those results: for groups A, B, and C, the test between easy and hard is significnat (p<.05), whereas for the control group that comparison is not significant. That is our interaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repeated measures ANOVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When your experimental design has measurements from the same people in multiple conditions you are in the realm of repeated measures ANOVA.\n",
    "\n",
    "A between participants ANOVA might measure the effect of performing some task under three different levels of distraction (low, medium, high), with different people assigned to each of the three distraction groups.\n",
    "\n",
    "If each person performed the task under each of the three different levels of distraction we would want to run a repeated measures ANOVA. \n",
    "\n",
    "The primary reason for the difference has to do with how the variance is accounted for or partitioned in the different settings and you can find abundant discussion of the details in your stats notes or in any number of online sources. In this notebook we'll focus on the mechanics of running the analysis in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A mixed design repeated measures dataset\n",
    "\n",
    "_(Thanks to Raphael Vallat for the example)_\n",
    "\n",
    "As an example, we will ask whether meditation can improve school performance in primary school students.\n",
    "\n",
    "The experimental design we'll use:\n",
    "\n",
    "- students are split into a control group and a meditation group\n",
    "    - meditation group: instructed to meditate for 20 minutes a day\n",
    "    - control group: instructed not to change their daily routine\n",
    "    - this is a **between-group factor**\n",
    "\n",
    "- to assess whether meditation improves or worsens performance over time each student is assessed on performance at three time points during the year\n",
    "    - august: time = 0\n",
    "    - january: time = 6 months\n",
    "    - june: time = 12 months\n",
    "    - This is a **within-person factor**\n",
    "\n",
    "Our data will have: the test scores (dependent variable), time of year (three levels; within participant), and meditation or control group (two levels; between participants). \n",
    "\n",
    "This is a \"mixed design\" because we have a mix of within (time of test) and between (meditation-yes, meditation-no) participants factors.\n",
    "\n",
    "A simulated dataset with this structure is saved in meditation.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load meditation.csv into dataframe called df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at data from one person using Boolean indexing on the 'Subject' column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check out the overall pattern of results visually using any number of seaborn plot types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or take a look at the mean and std for each group combination using groupby:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-way Repeated measures ANOVA\n",
    "\n",
    "First, let's just run a repeated measures ANOVA on one of our factors: Time. \n",
    "\n",
    "Each person was tested at three timepoints so looking at that factor gives us a pure within participant or repeated measures design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use pinguoin library for easy access to repeated measures ANOVA:\n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "rm_reslts = pg.rm_anova(data=some_data_frame, \n",
    "                        dv='outcome_variable', \n",
    "                        within='factor1', \n",
    "                        subject='variable_linking_factor1_measurements')\n",
    "```\n",
    "\n",
    "- 'data' is where the data live\n",
    "- 'dv' is the outcome variable, \n",
    "- 'within' is the predictor variable or IV \n",
    "- 'subject' is the column that links the different measurements together, telling pingouin which Time scores should be grouped together within participant ID\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run within person repeated measures ANOVA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results object is a dataframe and individual values can be accessed:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post-hoc tests in a one-way repeated measures design can be achieved \n",
    "# by a series of pairwise paired t-tests with an appropriate multiple comparisons\n",
    "# correction to the p-values\n",
    "\n",
    "# we can use pingouin pairwise_ttest() function to do this\n",
    "\n",
    "# dv is the dependent variable or outcome measure\n",
    "# within is the within person factor(s)\n",
    "# subject is a column that links within-person measurements of the within= variable(s)\n",
    "# data is where the dv, within, and subject variables are located\n",
    "# padjust is the method for p value adjustment for multiple comparisons\n",
    "\n",
    "pg.pairwise_ttests(dv='Scores', \n",
    "                   within='Time', \n",
    "                   subject='Subject', \n",
    "                   data=df,\n",
    "                   padjust='bonferroni')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running mixed design ANOVA\n",
    "\n",
    "Using an ANOVA to test the effect of meditation (or none) on scores over time will require the use of mixed design ANOVA that enables us to account for both the between groups factor (meditation vs control) and the within person, or repeated measures, factor of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To specify such a model in pingouin we need to define the dependent variable, the within subject factor, the between subject factor, and the id that links across repeated measures. In our data this latter value is in the 'Subject' column and this is what is used to match the scores over time within person.\n",
    "\n",
    "\n",
    "```python\n",
    "aov = pg.mixed_anova(dv='outcome_variable',\n",
    "                     within='within_subject_factor',\n",
    "                     between='between subject factor',\n",
    "                     subject='the column that links measuremets on the within factor',\n",
    "                     data=place_where_all_the_data_live)\n",
    "                     \n",
    "    \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results indicate a significant main effect of Group and Time as well as an interaction, but not which pairs of measurements differ from each other. Pingouin also provides a nice way to get all the pairwise tests using `pg.pairwise_ttests()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "posthocs = pg.pairwise_ttests(dv='Scores', \n",
    "                              within='Time', \n",
    "                              between='Group',\n",
    "                              subject='Subject', \n",
    "                              data=df)\n",
    "posthocs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, that's a lot of pairwise tests to run, so if we want to use a corrected p value we can add in the padju= argument to the pairwise_ttests() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.pairwise_ttests(dv='Scores', \n",
    "                   within='Time', \n",
    "                   between='Group', \n",
    "                   subject='Subject',\n",
    "                   data=df, \n",
    "                   padjust='bonf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check the documentation for other p value adjustment methods:\n",
    "\n",
    "'none': no correction\n",
    "\n",
    "'bonf': one-step Bonferroni correction\n",
    "\n",
    "'sidak': one-step Sidak correction\n",
    "\n",
    "'holm': step-down method using Bonferroni adjustments\n",
    "\n",
    "'fdr_bh': Benjamini/Hochberg FDR correction\n",
    "\n",
    "'fdr_by': Benjamini/Yekutieli FDR correction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook begins to introduce tools for running one-way, multi-way, repeated measures, and mixed design ANOVAs in Python using statsmodels and pingouin."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
