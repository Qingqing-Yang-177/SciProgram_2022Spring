{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining data frames\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many situations when you might want to combine seprate pandas dataframes into a single dataframe.\n",
    "\n",
    "Sometimes this will be combining data frames with the same columns and we want to stack the dataframes. For example, you might have experiment data from individual participants and want to combine them into a dataframe that has data from all participants. This is usually done using the pandas `concat()` function.\n",
    "\n",
    "Other times you might like to combine dataframes that contain different information or columns. For example, we might have a dataframe that has behavioral data from a set of participants in an experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For many of these examples I'd like to be able to generate fake data for participants in an experiment. To make life simpler (and make code more readable) I have defined a function that makes simulated data for a participant in an experiment.\n",
    "\n",
    "The function takes in arguments for user id and (optionally) the number of trials they participated in.\n",
    "\n",
    "The function returns a dataframe with the following columns:\n",
    "\n",
    "    df = pd.DataFrame({'uid': str(uid),\n",
    "                       'response': response,\n",
    "                       'acc': acc,\n",
    "                       'trial_type': trial_type,\n",
    "                       'RT': RT\n",
    "                      })\n",
    "    \n",
    "\n",
    "\n",
    "`uid`: a participant id (string)\n",
    "\n",
    "`response`: the button the person pressed (random integer 1 to 4)\n",
    "\n",
    "`acc`: whether they got the trial correct (1) or incorrect (0)\n",
    "\n",
    "`trial_type`: congruent or incongruent, roughly corresponding to easy and hard (string)\n",
    "\n",
    "`RT`: response time, random number > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_participant_data(uid, n_trials=100, cond_diffs=True):\n",
    "    '''\n",
    "    Makes fake participant data and returns a dataframe.\n",
    "\n",
    "            Parameters:\n",
    "                    uid (str, int): An id for the participant\n",
    "                    n_trials  (int): Number of trials worth \n",
    "                                        of data\n",
    "                    cond_diffs (boolean): Whether to simulate \n",
    "                                            data with differences \n",
    "                                            between conditions\n",
    "                    \n",
    "\n",
    "            Returns:\n",
    "                    df (dataframe): A dataframe of simulated data \n",
    "                                        with one row for each trial \n",
    "                                        and columns:\n",
    "                                            uid: participant id\n",
    "                                            trial_type: experimental condition\n",
    "                                            resp: response\n",
    "                                            acc: accuracy (1/0)\n",
    "                                            RT: response time\n",
    "    '''\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from random import shuffle\n",
    "    \n",
    "    # Check whether desired n_trials is divisible by two by\n",
    "    # checking whether the remainder of n_trials divided by \n",
    "    # two is 0 (even number) or not. If not, the assert statement\n",
    "    # will exit the function after printing the message:\n",
    "    assert n_trials%2 == 0, 'n_trials must be divisible by two'\n",
    "    \n",
    "    \n",
    "    # get n_trials worth of random integers between 1 and 4 (5 excluded)\n",
    "    response = np.random.randint(1,5,n_trials)\n",
    "    \n",
    "    # get n_trials worth of binary (1 or 0) integer accuracy scores   \n",
    "    acc = np.random.randint(0,2, n_trials)\n",
    "    \n",
    "    # --- trial_type\n",
    "    # make a list with our possible trial types\n",
    "    cond_list = ['congruent', 'incongruent']\n",
    "\n",
    "    # make a list equal to total number of trials\n",
    "    # multiple the list by n_trials/2 because there \n",
    "    # are two elements of tt\n",
    "    trial_type = [cond_list[0]]*int((n_trials/2))+[cond_list[1]]*int((n_trials/2)) \n",
    "\n",
    "    \n",
    "    # shuffle the list using the shuffle() function from the \n",
    "    # random library\n",
    "    shuffle(trial_type)\n",
    "    #----------------------------\n",
    "    \n",
    "    # get n_trials worth response time values between\n",
    "    if cond_diffs:\n",
    "        # loop over conditions and use different\n",
    "        # values of mean for random.normal\n",
    "        # initialize RT array\n",
    "        RT = np.array([])\n",
    "        for c in range(len(cond_list)):\n",
    "            t = abs(npr.normal(c+1,1, int(n_trials/2)))\n",
    "            RT = np.concatenate([RT, t])\n",
    "    else:\n",
    "        RT = abs(npr.normal(1,1, n_trials))\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    # make a dataframe from a dictionary of column names (keys) and\n",
    "    # data values\n",
    "    df = pd.DataFrame({'uid': str(uid),\n",
    "                       'response': response,\n",
    "                       'acc': acc,\n",
    "                       'trial_type': trial_type,\n",
    "                       'RT': RT\n",
    "                      })\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating\n",
    "\n",
    "Pandas provides convenient tools for concatenating individual dataframes together into a single frame. An example of when this can be useful is combining data from individual participants in the same experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the make_participant_data() function to get dataframes with data for four 'participants' in our 'experiment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = make_participant_data('sub-18', n_trials=6)\n",
    "df2 = make_participant_data('sub-19', n_trials=6)\n",
    "df3 = make_participant_data('sub-33', n_trials=6)\n",
    "df4 = make_participant_data('sub-08', n_trials=6)\n",
    "\n",
    "df4.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the last cell worked, but when we have the same code repeated several times in a row it's often better to put it in a for loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: Make individual dataframes\n",
    "\n",
    "For each participant in the list `all_subs = ['sub-18','sub-19', 'sub-33', 'sub-08']` use the `make_participant_data()` function with n_trials = 100 to make individual dataframes. The individual dataframes should be stored in a list called `df_list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a list of dataframes with participant data\n",
    "all_subs = ['sub-18','sub-19', 'sub-33', 'sub-08']\n",
    "df_list = []\n",
    "\n",
    "# fill in code here:\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a set of dataframes stored in their own variables. Each dataframe has data for a series of trials in the experiment. Rows correspond to trials and columns are different kinds of data we measured. \n",
    "\n",
    "If we want a dataframe that has all the data from all the participants we can use `pd.concat()` to stack them vertically.\n",
    "\n",
    "`pd.concat()` takes a list of dataframes as input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can do it this way if individual dataframes are stored in \n",
    "# their own variables:\n",
    "\n",
    "pd.concat([df1, df2, df3, df4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or the equivalent if you already have a list of dataframes\n",
    "# the ignore_index=True will ignore the index (row labels)\n",
    "# in the original dataframes and just renumber everything\n",
    "# 0 to n-1\n",
    "all_participants = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "all_participants\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a dataframe with all the participants in it. We can use pandas .unique() function to check which values are in the uid column of our new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.unique(all_participants['uid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In previous sections we used `.groupby()` to take different views on our data by combining them according to different value in the dataframe.\n",
    "\n",
    "For example, let's check the average of the columns in the dataframe after separating the data according to trial_type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the top of the dataframe and we see two trial_types\n",
    "all_participants.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or use unique to verify all the different trial_types\n",
    "all_participants['trial_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the average accuracy and response time for \n",
    "# each trial type:\n",
    "all_participants.groupby('trial_type').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the output did not include the 'mean' of the uid column and this is good, because it has strings in it and the average of 'sub-11', 'sub-18', 'sub-33', etc is not very meaningful.\n",
    "\n",
    "Restrict the previous view to just the 'RT' column of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_participants.groupby('trial_type')['RT'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or get lots of descriptive stats for the 'RT' column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_participants.groupby('trial_type')['RT'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: Get mean RT for each participant in `all_participants` dataframe\n",
    "\n",
    "Earlier in this notebook you saw an example of getting mean RT for each trial_type. Now do it for each participant id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_participants.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean response time (RT column) for each person\n",
    "# in the uid column separated by trial type:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: make a bar graph with percent correct (acc column) as the y value and a separate bar for each participant in the all_participants dataframe\n",
    "\n",
    "**hint**: use seaborn catplot(). Catplot with kind=bar will give us the average of whatever we put in the y= value. In our data the acc column is binary 1/0 and the average of that will be the percent correct, or proportion of entries that are equal to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a plot for percent correct for each person:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could keep on analyzing the data, but the main thing from this section is to notice how using pd.concat() and inputting a list of dataframes makes a new dataframe with all the input df's stacked up vertically. If they have the same columns the result makes sense.\n",
    "\n",
    "You can also use pd.concat() if df's have different columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_participants.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a different dataframe with some other columns\n",
    "df99 = pd.DataFrame({'uid': 'sub-99', \n",
    "                     'response_time': np.random.uniform(1000,5000, 6)})\n",
    "df99.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use pd.concat() to stack df1 and df99:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [df1, df99]\n",
    "\n",
    "combined_df = pd.concat(df_list, ignore_index=True)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, if the df's to be concatenated don't have the same columns, the output has all of the columns that appeared in any of the input list. Any rows of the data that come from a dataframe that didn't have that column get NaN (not a number) in that cell.\n",
    "\n",
    "\n",
    "So in our example sub-18 has no values for 'response_time' because df1 didn't have that column and sub-99 has no data for response, correct trial_type, and RT because df99 didn't have those columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging dataframes\n",
    "\n",
    "The preceding examples showed __concatenating__ or glueing together some dataframes.\n",
    "\n",
    "Another common need is to combine dataframes that have different information for the same person.\n",
    "\n",
    "In the next examples we will use pd.merge() to combine 'experiment data' from our participants that we already made with 'demographics' data for the same people."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next cell defines a function that takes in a participant id (uid) return a dataframe that randomly assigns them to a location (urban, rural) and an age_troup (child, adult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convenience function to get random demographic info for a person\n",
    "def make_demo_data(uid):\n",
    "   \n",
    "    import random\n",
    "    \n",
    "    locations = ['urban','rural']\n",
    "    age_group = ['child', 'adult']\n",
    "    \n",
    "    demo_df = pd.DataFrame({'uid': [uid],\n",
    "                            'location': [random.choice(locations)],\n",
    "                            'age_group': [random.choice(age_group)]\n",
    "                           })\n",
    "    return demo_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df101 = make_demo_data('sub-19')\n",
    "df101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make new experimental data and combine the \n",
    "# individual participant data into a group dataframe\n",
    "# this uses or make_participant_data() that we defined\n",
    "# at the beginning of this notebook\n",
    "df1 = make_participant_data('sub-18', n_trials=56)\n",
    "df2 = make_participant_data('sub-19', n_trials=56)\n",
    "df3 = make_participant_data('sub-33', n_trials=56)\n",
    "df4 = make_participant_data('sub-08', n_trials=56)\n",
    "\n",
    "# use pd.concat to put them together\n",
    "all_exp_data = pd.concat([df1, df2, df3, df4], ignore_index=True)\n",
    "all_exp_data.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make new demographic data and combine the \n",
    "# individual participant data into a group dataframe\n",
    "# use our make_demo_data() function\n",
    "df101 = make_demo_data('sub-18')\n",
    "df102 = make_demo_data('sub-19')\n",
    "df103 = make_demo_data('sub-33')\n",
    "df104 = make_demo_data('sub-08')\n",
    "\n",
    "all_demo_data = pd.concat([df101, df102, df103, df104], ignore_index=True)\n",
    "\n",
    "all_demo_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the experimental data for each person in one dataframe and the demographics in another. What if we want to do some analyses that involve grouping the behavioral data observations according to demographic data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of using `pd.concat()` we will use the `pd.merge()` function. First let's run it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.merge(left=all_exp_data, \n",
    "                       right=all_demo_data)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our output now has all the columns we want, and we have the demographic data values lined up with the experimental data for each person listed in the uid column.\n",
    "\n",
    "When we used merge() we gave it two inputs, `left=` and `right=`. These inputs corresponded to the dataframes we want to merge.\n",
    "\n",
    "By default, merge() looks for any columns with the same name in the two input dataframes. Then it takes those columns and lines up the dataframes according to the values in them.\n",
    "\n",
    "We can also specify which column values should be matched by including the `on=` argument to merge():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.merge(left=all_exp_data, \n",
    "                       right=all_demo_data, \n",
    "                       on='uid')\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the `on=` argument is especially useful if you have dataframes with different column names for the same underlying data. Here we will rename the 'uid' column in all_demo_data and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_demo_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe rename function takes a dictionary mapping old names (keys) to new names (values)\n",
    "# inplace=True means change the existing dataframe (rather than outputting to a new variable)\n",
    "\n",
    "all_demo_data.rename(columns={'uid': 'ID_num', 'location': 'loc'}, \n",
    "                     inplace=True)\n",
    "all_demo_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try merging two dataframes that don't have overlapping column names:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the column names in each dataframe:\n",
    "print(all_exp_data.columns)\n",
    "print(all_demo_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_df = pd.merge(left=all_exp_data, right=all_demo_data)\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That gave us an error and the error said \"No common columns to perform merge on.\"\n",
    "\n",
    "The solution is to tell .merge() which columns in the left and right df to merge on, or use for the merge:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we tell pd.merge to use 'uid' column in the \n",
    "# left= dataframe and line those values up with the\n",
    "# ID_num column in the right= dataframe\n",
    "combined_df = pd.merge(left=all_exp_data, \n",
    "                       right=all_demo_data, \n",
    "                       left_on='uid', \n",
    "                       right_on='ID_num')\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see that it worked, lining up rows according to matching values in 'uid' and 'ID_num' columns in the two dataframes. It also kept both columns by default in the combined_df. We can drop one of those if we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del combined_df['ID_num']\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: practice merging dataframes\n",
    "\n",
    "The next cell defines another dataframe that gives us some information about people in age_groups child and adult.\n",
    "\n",
    "Try to merge the `age_df` with our existing `combined_df` so that we have the `expected_value` for each age_group in the combined_df. In age_df the relevant column is called 'ages':\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_df = pd.DataFrame({'ages': ['child', 'adult'],\n",
    "         'expected_value': [0,99]})\n",
    "age_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the top of the combined_df\n",
    "combined_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code for merging combined_df and age_df goes here\n",
    "# they should be merged using the 'age_group' column\n",
    "# in combined_df and the 'ages' column in the age_df\n",
    "# Store the results of the merge in a variable\n",
    "# called combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take a look at the merged dataframe:\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using .query() to get subsets of dataframes\n",
    "\n",
    "We can use the dataframe `.query()` method to get portions of a dataframe according to some conditions. \n",
    "\n",
    "The .query() method helps us achieve things similar to what we did with boolean indexing previously, using things like:\n",
    "\n",
    "    df[df['column_name]=='some value]\n",
    "    \n",
    "Some people find the query() syntax easier to deal with (although note the use of single and double quotes to handle strings. It is good to be familiar with both approaches.\n",
    "\n",
    "\n",
    "Here we use query() it to get the parts of a single participant dataframe where trial_type is \"incongruent\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_incong = df1.query('trial_type == \"incongruent\"')\n",
    "df_incong.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The syntax is straightforward. Put the conditions to be met inside of query and you'll get back any rows that match that condition. Because the input to query is a string, we had to put additional quotes around \"incongruent\" so that would be interepreted as a string.\n",
    "\n",
    "Multiple expressions can be met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1.query('trial_type == \"incongruent\" and acc==1').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to store some of the conditions to check in a variable we precede them the '@' symbol in the query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = 'incongruent'\n",
    "\n",
    "df1.query('trial_type == @tt and acc == 0').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise: query on mutliple conditions\n",
    "\n",
    "Try using the query() syntax on the combined_df to pull out only the data where age is child, trial_type is congruent, and acc is 1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['ages'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your query goes here:\n",
    "# note that if your randomly end up with only \n",
    "# adults in your dataframe this query will be empty\n",
    "tt = 'congruent'\n",
    "a = 'child'\n",
    "accuracy = 1\n",
    "combined_df.query('trial_type==@tt and age_group==@a and acc==@accuracy')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
